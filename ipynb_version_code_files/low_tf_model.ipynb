{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"low_tf_model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"14vgiYldzazmymS4LyPUXDjpJk9CsQHgj","authorship_tag":"ABX9TyM9DI/h6IudJfbMwvKW93Rl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import json\n","import pandas as pd\n","import csv\n","import os\n","import sys\n","import pickle\n","import numpy as np\n","from random import random\n","import math\n","import torch\n","import torchvision \n","import torch.nn.functional as F  \n","import torchvision.datasets as datasets  \n","import torchvision.transforms as transforms  \n","from torch import optim  \n","from torch import nn  \n","from torch.utils.data import DataLoader  \n","from tqdm import tqdm  \n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","import copy"],"metadata":{"id":"V60vJZ-J31Vp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parentPath = os.getcwd()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"0hiJfWHq4Gs0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Loading saved model**"],"metadata":{"id":"OAW8MHMDKFga"}},{"cell_type":"code","source":["class NN(nn.Module):\n","  def __init__(self, input_size=127):\n","    super(NN, self).__init__()\n","\n","    self.NN_tumor = nn.Sequential(nn.Linear(input_size, 64), nn.ReLU(),\n","                            nn.Linear(64, 96), nn.ReLU(),\n","                            nn.Linear(96, 128), nn.ReLU(),\n","                            nn.Linear(128, 128), nn.ReLU())\n","    \n","    self.NN_blood = nn.Sequential(nn.Linear(input_size, 64), nn.ReLU(),\n","                            nn.Linear(64, 96), nn.ReLU(),\n","                            nn.Linear(96, 128), nn.ReLU(),\n","                            nn.Linear(128, 128), nn.ReLU())\n","    \n","    self.NN_join = nn.Sequential(nn.Linear(256, 64), nn.ReLU(),\n","                            nn.Linear(64, 96), nn.ReLU(),\n","                            nn.Linear(96, 128), nn.ReLU(),\n","                            nn.Linear(128, 1))\n","    \n","  def forward(self, x):\n","    x0, x1 = x[:, 0, :], x[:, 1, :]\n","    x0 = self.NN_tumor(x0)\n","    x1 = self.NN_blood(x1)\n","    x = torch.cat((x0, x1), 1)\n","    x = torch.squeeze(self.NN_join(x))\n","    return x\n","\n","model_path = 'models/low_model.pt'\n","low_model = NN().to(device)\n","if device == 'cuda':\n","  low_model.load_state_dict(torch.load(model_path))\n","else:\n","  low_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"],"metadata":{"id":"eJqhNLei4LTM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Loading and normalizing extracted features**"],"metadata":{"id":"dLP6EvdSKJlD"}},{"cell_type":"code","source":["data_dict = {}\n","with open('Intermediate_Files/low_data.pkl', 'rb') as f:\n","  data_dict = pickle.load(f)\n","data = data_dict['samples']\n","sample_names = data_dict['meta_info']\n","\n","max_arr = np.load('meta_info/max_arr.npy')\n","sums = np.sum(data, axis=2)\n","data = data/ sums[:, :, np.newaxis]\n","data = data/ max_arr"],"metadata":{"id":"uWmPf5Wy43yO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Saving tumor fraction predictions as intermediate files**"],"metadata":{"id":"57--T08mKO4f"}},{"cell_type":"code","source":["csv_list = []\n","low_model.eval()\n","with torch.no_grad():\n","  for i in range(data.shape[0]):\n","      dataX = torch.tensor(data[i]).type(torch.float)\n","      dataX = torch.unsqueeze(dataX, 0)\n","      score = low_model(dataX.to(device))\n","      csv_list.append([sample_names[i], np.round(score.item(),5)])\n","        \n","filePath = 'Intermediate_Files/low_predictions.csv'\n","my_df = pd.DataFrame(csv_list)\n","my_df.to_csv(filePath, index=False, header=['Sample_ID', 'Pred_TF'])"],"metadata":{"id":"XDmX2-J25ec-"},"execution_count":null,"outputs":[]}]}