{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"high_tf_model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1KCTr2ZgkLfOtwqjR1tHC8I9kpPo4FRRE","authorship_tag":"ABX9TyNBbi7R+kBtjXOvVPhaxy1K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"U85j799DLgbQ"},"outputs":[],"source":["# you need to do this if you have python version less than 3.8\n","!pip3 install pickle5"]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import numpy as np\n","import torchvision.models\n","from torch import Tensor\n","import json\n","import os\n","import pickle5 as pickle\n","import pandas as pd"],"metadata":{"id":"6MQGvWe-HxHm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parentPath = os.getcwd()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"vSPHn3PxGcOP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Loading model configuration files and the model**"],"metadata":{"id":"CHY5pmPALD1S"}},{"cell_type":"code","source":["class MLPLayer(nn.Module):\n","    def __init__(self, hidden_dimension):\n","        super(MLPLayer, self).__init__()\n","        self.hidden_dimension = hidden_dimension\n","        self.linear_layer = nn.Linear(\n","            self.hidden_dimension, self.hidden_dimension\n","            )\n","        self.bn = nn.BatchNorm1d(\n","            self.hidden_dimension\n","            )\n","    def forward(self, x: Tensor) -> Tensor:\n","        x_in = x\n","        x = self.linear_layer(x)\n","        x = self.bn(x)\n","        x = F.relu(x)\n","        x = x + x_in\n","        return x\n","class CFDNAModel(nn.Module):\n","    def __init__(self, config, tumor_fraction_stats):\n","        super(CFDNAModel, self).__init__()\n","        # Define net parameters\n","        self.tumor_fraction_stats = tumor_fraction_stats\n","        if torch.cuda.is_available():\n","            self.dtypeFloat = torch.cuda.FloatTensor\n","            self.device = \"cuda\"\n","        else:\n","            self.dtypeFloat = torch.FloatTensor\n","            self.device = \"cpu\"\n","        #self.log_offset = config.log_offset\n","        self.smallest_tumor_fractions = config.smallest_tumor_fractions\n","        self.regression_dimension = config.regression_dimension\n","        self.classification_dimension = config.classification_dimension\n","        self.signal_dimension = 350\n","        self.imagenet_finetune = config.imagenet_finetune\n","        #self.motif_dimension = config.motif_dimension\n","        self.number_mlp_layers = config.number_mlp_layers\n","        self.dropout_rate = config.dropout_rate\n","        self.hidden_dimension = config.hidden_dimension\n","        #TODO: Util function to normalize tumor fractions\n","        self.zero_tumor_fractions_norm = (0 - self.tumor_fraction_stats[\"mean\"])/self.tumor_fraction_stats[\"std\"]\n","        self.smallest_tumor_fractions_norm = (self.smallest_tumor_fractions - self.tumor_fraction_stats[\"mean\"])/self.tumor_fraction_stats[\"std\"]\n","        self.one_tumor_fractions_norm = (1 -self. tumor_fraction_stats[\"mean\"])/self.tumor_fraction_stats[\"std\"]\n","        self.embedding_layer = nn.Linear(\n","           self.signal_dimension, self.hidden_dimension\n","           )\n","        self.embedding_layer_2_reg = nn.Linear(\n","            self.hidden_dimension, self.hidden_dimension\n","        )\n","        self.embedding_layer_3_reg = nn.Linear(\n","            self.hidden_dimension, self.hidden_dimension\n","        )\n","        self.embedding_layer_2_class = nn.Linear(\n","            self.hidden_dimension, self.hidden_dimension\n","        )\n","        self.embedding_layer_3_class = nn.Linear(\n","            self.hidden_dimension, self.hidden_dimension\n","        )\n","        self.bn = nn.BatchNorm1d(\n","            self.hidden_dimension\n","            )\n","        self.bn_2_reg = nn.BatchNorm1d(\n","            self.hidden_dimension\n","            )\n","        self.bn_3_reg = nn.BatchNorm1d(\n","            self.hidden_dimension\n","            )\n","        self.bn_2_class = nn.BatchNorm1d(\n","            self.hidden_dimension\n","            )\n","        self.bn_3_class = nn.BatchNorm1d(\n","            self.hidden_dimension\n","            )\n","        mlp_layers = []\n","        for layer in range(self.number_mlp_layers):\n","            mlp_layers.append(MLPLayer(self.hidden_dimension))\n","        self.mlp_layers = nn.ModuleList(mlp_layers)\n","        self.regression_layer = nn.Linear(\n","            self.hidden_dimension, self.regression_dimension\n","            )\n","        self.classification_layer = nn.Linear(\n","            self.hidden_dimension, self.classification_dimension\n","            )\n","        self.dropout_layer = nn.Dropout(\n","            self.dropout_rate\n","            )\n","    def forward(self, signal):\n","        # Node and edge embedding\n","        x = self.embedding_layer(signal)\n","        x = self.bn(x)\n","        x = F.relu(x)\n","        for i in range(self.number_mlp_layers):\n","            x = self.mlp_layers[i](x)\n","        x = self.dropout_layer(x)\n","        x_reg = self.embedding_layer_2_reg(x)\n","        x_reg = self.bn_2_reg(x_reg)\n","        x_reg = F.relu(x_reg)\n","        x_reg = self.embedding_layer_3_reg(x_reg)\n","        x_reg = self.bn_3_reg(x_reg)\n","        x_reg = F.relu(x_reg)\n","        x_class = self.embedding_layer_2_class(x)\n","        x_class = self.bn_2_class(x_class)\n","        x_class = F.relu(x_class)\n","        x_class = self.embedding_layer_3_class(x_class)\n","        x_class = self.bn_3_class(x_class)\n","        x_class = F.relu(x_class)\n","        y_pred_class = self.classification_layer(x_class)\n","        y_pred_reg = self.regression_layer(x_reg)\n","        return y_pred_reg, torch.squeeze(y_pred_class)\n","\n","\n","    def __unnormalize(self, pred_reg):\n","        return (\n","            self.tumor_fraction_stats[\"std\"] * pred_reg\n","            + self.tumor_fraction_stats[\"mean\"]\n","        )\n","\n","\n","    def __tumor_fraction_clipping(self, pred_reg, normalize = False):\n","\n","        if normalize:\n","            pred_reg[pred_reg < self.zero_tumor_fractions_norm] = self.zero_tumor_fractions_norm\n","            pred_reg[pred_reg > self.one_tumor_fractions_norm] = self.one_tumor_fractions_norm\n","\n","        else:\n","            pred_reg[pred_reg < 0] = 0\n","            pred_reg[pred_reg > 1] = 1\n","\n","        return pred_reg\n","\n","\n","    def output(self, pred_reg, pred_prob):\n","        regression_unnormalize = self.__unnormalize(pred_reg)\n","        regression_unnormalize = self.__tumor_fraction_clipping(regression_unnormalize)\n","        classification_prediction = torch.sigmoid(torch.squeeze(pred_prob))\n","        regression_final = regression_unnormalize\n","        return regression_final, regression_unnormalize, classification_prediction"],"metadata":{"id":"SW7UVXdXEdEe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Settings(dict):\n","    def __init__(self, config_dict):\n","        super().__init__()\n","        for key in config_dict:\n","            self[key] = config_dict[key]\n","\n","    def __getattr__(self, attr):\n","        return self[attr]\n","\n","    def __setitem__(self, key, value):\n","        return super().__setitem__(key, value)\n","\n","    def __setattr__(self, key, value):\n","        return self.__setitem__(key, value)\n","\n","    __delattr__ = dict.__delitem__\n","\n","def get_config(filepath):\n","    config = (Settings(json.load(open(filepath))))\n","    return config\n","\n","config_train_path = 'meta_info/train.json'\n","config_train = get_config(config_train_path)"],"metadata":{"id":"Pjg5j1M5ExZc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["signals_stats = {}\n","with open('meta_info/signals_stats.pkl', 'rb') as f:\n","  signals_stats = pickle.load(f)\n","\n","tumor_fractions_stats = {}\n","with open('meta_info/tumor_fractions.pkl', 'rb') as f:\n","  tumor_fractions_stats = pickle.load(f)"],"metadata":{"id":"kW0Uz29_GBvo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = nn.DataParallel(CFDNAModel(config_train, tumor_fractions_stats))\n","# Load checkpoint\n","checkpoint = None\n","if torch.cuda.is_available():\n","  net.cuda()\n","  checkpoint = torch.load(\"models/high_model.tar\")\n","else:\n","  checkpoint = torch.load(\"models/high_model.tar\", map_location='cpu')\n","# Load network state\n","net.load_state_dict(checkpoint['net_state_dict'])"],"metadata":{"id":"air4-mEIH8rV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Data loading and normalizing**"],"metadata":{"id":"73b8tNwfLXmY"}},{"cell_type":"code","source":["data_dict = {}\n","with open('Intermediate_Files/high_data.pkl', 'rb') as f:\n","  data_dict = pickle.load(f)\n","data = data_dict['samples']\n","sample_names = data_dict['meta_info']"],"metadata":{"id":"zHVHg6ZFLdXA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataProcess(signal):\n","  # max count normalize\n","  signal = signal + 1\n","  signal = signal / signal[np.argmax(signal)]\n","  # log\n","  signal = np.log10(signal)\n","  # running mean and std normalize\n","  filter_window = 32\n","  mean_signal, std_signal = [], []\n","  length_signal = len(signal)\n","  signal_pad = np.pad(signal, (filter_window//2, filter_window//2), mode = \"edge\")\n","  for i in range(0, length_signal):\n","    begin = i\n","    end = i + filter_window\n","    sliced_signal = signal_pad[begin:end]\n","    mean_signal.append(np.mean(sliced_signal))\n","    std_signal.append(np.std(sliced_signal))\n","  std_signal[std_signal == 0] = 1e-6\n","  signal = np.array((signal - mean_signal)/std_signal, dtype=\"float32\")\n","  # training stats mean and std columnwise normalize\n","  signal = (signal - signals_stats[\"mean\"])/ signals_stats[\"std\"]\n","  return signal"],"metadata":{"id":"1sOO5mXUFajq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Saving predictions**"],"metadata":{"id":"b91PArd9LvIg"}},{"cell_type":"code","source":["csv_list = []\n","net.eval()\n","with torch.no_grad():\n","  for i in range(data.shape[0]):\n","      dataX = dataProcess(data[i])\n","      dataX = torch.tensor(dataX).type(torch.float)\n","      dataX = torch.unsqueeze(dataX, 0)\n","      y_pred_reg, y_pred_class = net.forward(dataX)\n","      score, _, _ = net.module.output(y_pred_reg, y_pred_class)\n","      csv_list.append([sample_names[i], np.round(score.item(),5)])\n","        \n","filePath = 'Intermediate_Files/high_predictions.csv'\n","my_df = pd.DataFrame(csv_list)\n","my_df.to_csv(filePath, index=False, header=['Sample_ID', 'Pred_TF']) "],"metadata":{"id":"17ahujqcKFWg"},"execution_count":null,"outputs":[]}]}